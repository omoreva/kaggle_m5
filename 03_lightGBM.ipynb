{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Light GBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use tree-based algorithms since they are powerful and do not impose strict assumptions on features like linearity or independence. Light GBM is a fast algorithm with lower memory usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime  import datetime  \n",
    "from datetime import timedelta  \n",
    "import lightgbm as lgb\n",
    "from sklearn import preprocessing, metrics\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import mlflow\n",
    "import mlflow.lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_pickle('../01_preprocessed_data/X_train.pkl')\n",
    "y_train = pd.read_pickle('../01_preprocessed_data/y_train.pkl')\n",
    "X_val = pd.read_pickle('../01_preprocessed_data/X_val.pkl')\n",
    "y_val = pd.read_pickle('../01_preprocessed_data/y_val.pkl')\n",
    "X_test = pd.read_pickle('../01_preprocessed_data/X_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_location = '../00_data/sample_submission.csv'\n",
    "submission = pd.read_csv(data_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set parameters of the light GBM and select features to fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42644016, 35)\n",
      "(1706991, 35)\n",
      "(853720, 35)\n",
      "(42644016, 1)\n",
      "(1706991, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'metric': 'rmse',\n",
    "        'objective':  'poisson',\n",
    "        'n_jobs': -1,\n",
    "        'seed': 0,\n",
    "        'learning_rate': 0.1, \n",
    "        'bagging_fraction': 0.75,\n",
    "        'bagging_freq': 10, \n",
    "        'colsample_bytree': 0.75}\n",
    "not_features = ['d', 'id', 'demand', 'date', 'start_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid ={'boosting_type': ['gbdt'],\n",
    "        'metric': ['rmse'],\n",
    "        'objective': ['poisson', 'tweedie'],\n",
    "        'n_jobs': [-1],\n",
    "        'seed': [0],\n",
    "        'learning_rate':  [0.05, 0.075, 0.1],\n",
    "        'bagging_fraction': [0.5, 0.75, 1],\n",
    "        'bagging_freq': [10], \n",
    "        'colsample_bytree': [0.75],\n",
    "        'num_iterations': [1000],\n",
    "        'early_stopping_round': [100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = X_test.columns[~X_test.columns.isin(not_features)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = lgb.Dataset(X_train[features], y_train) #, categorical_feature = categorical_features)\n",
    "val_set = lgb.Dataset(X_val[features], y_val)#,  categorical_feature = categorical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgb.train(params, train_set,  \n",
    "                  valid_sets = [train_set, val_set], verbose_eval = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "{'bagging_fraction': 0.5, 'bagging_freq': 10, 'boosting_type': 'gbdt', 'colsample_bytree': 0.75, 'early_stopping_round': 100, 'learning_rate': 0.05, 'metric': 'rmse', 'n_jobs': -1, 'num_iterations': 1000, 'objective': 'poisson', 'seed': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\omore\\Anaconda3\\lib\\site-packages\\mlflow\\utils\\autologging_utils.py:60: DeprecationWarning: inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
      "  all_param_names, _, _, all_default_values = inspect.getargspec(fn)  # pylint: disable=W1505\n",
      "C:\\Users\\omore\\Anaconda3\\lib\\site-packages\\mlflow\\lightgbm.py:285: DeprecationWarning: inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
      "  all_arg_names = inspect.getargspec(original)[0]  # pylint: disable=W1505\n",
      "C:\\Users\\omore\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\omore\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.69298\tvalid_1's rmse: 2.24843\n",
      "[200]\ttraining's rmse: 2.63642\tvalid_1's rmse: 2.21803\n",
      "[300]\ttraining's rmse: 2.60652\tvalid_1's rmse: 2.2151\n",
      "[400]\ttraining's rmse: 2.58173\tvalid_1's rmse: 2.21307\n",
      "[500]\ttraining's rmse: 2.56216\tvalid_1's rmse: 2.21115\n",
      "Early stopping, best iteration is:\n",
      "[460]\ttraining's rmse: 2.56838\tvalid_1's rmse: 2.20982\n",
      "------------------------------------\n",
      "1\n",
      "{'bagging_fraction': 0.5, 'bagging_freq': 10, 'boosting_type': 'gbdt', 'colsample_bytree': 0.75, 'early_stopping_round': 100, 'learning_rate': 0.05, 'metric': 'rmse', 'n_jobs': -1, 'num_iterations': 1000, 'objective': 'tweedie', 'seed': 0}\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.72587\tvalid_1's rmse: 2.22466\n",
      "[200]\ttraining's rmse: 2.65079\tvalid_1's rmse: 2.2141\n",
      "Early stopping, best iteration is:\n",
      "[141]\ttraining's rmse: 2.68364\tvalid_1's rmse: 2.2075\n",
      "------------------------------------\n",
      "2\n",
      "{'bagging_fraction': 0.5, 'bagging_freq': 10, 'boosting_type': 'gbdt', 'colsample_bytree': 0.75, 'early_stopping_round': 100, 'learning_rate': 0.075, 'metric': 'rmse', 'n_jobs': -1, 'num_iterations': 1000, 'objective': 'poisson', 'seed': 0}\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.67788\tvalid_1's rmse: 2.23664\n",
      "[200]\ttraining's rmse: 2.62307\tvalid_1's rmse: 2.22419\n",
      "[300]\ttraining's rmse: 2.57791\tvalid_1's rmse: 2.2185\n",
      "[400]\ttraining's rmse: 2.54751\tvalid_1's rmse: 2.21795\n",
      "Early stopping, best iteration is:\n",
      "[382]\ttraining's rmse: 2.55068\tvalid_1's rmse: 2.21587\n",
      "------------------------------------\n",
      "3\n",
      "{'bagging_fraction': 0.5, 'bagging_freq': 10, 'boosting_type': 'gbdt', 'colsample_bytree': 0.75, 'early_stopping_round': 100, 'learning_rate': 0.075, 'metric': 'rmse', 'n_jobs': -1, 'num_iterations': 1000, 'objective': 'tweedie', 'seed': 0}\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.67857\tvalid_1's rmse: 2.21569\n",
      "[200]\ttraining's rmse: 2.61788\tvalid_1's rmse: 2.22061\n",
      "Early stopping, best iteration is:\n",
      "[108]\ttraining's rmse: 2.67097\tvalid_1's rmse: 2.2137\n",
      "------------------------------------\n",
      "4\n",
      "{'bagging_fraction': 0.5, 'bagging_freq': 10, 'boosting_type': 'gbdt', 'colsample_bytree': 0.75, 'early_stopping_round': 100, 'learning_rate': 0.1, 'metric': 'rmse', 'n_jobs': -1, 'num_iterations': 1000, 'objective': 'poisson', 'seed': 0}\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.67497\tvalid_1's rmse: 2.24066\n",
      "[200]\ttraining's rmse: 2.5981\tvalid_1's rmse: 2.23089\n",
      "[300]\ttraining's rmse: 2.55403\tvalid_1's rmse: 2.22768\n",
      "Early stopping, best iteration is:\n",
      "[262]\ttraining's rmse: 2.56618\tvalid_1's rmse: 2.22638\n",
      "------------------------------------\n",
      "5\n",
      "{'bagging_fraction': 0.5, 'bagging_freq': 10, 'boosting_type': 'gbdt', 'colsample_bytree': 0.75, 'early_stopping_round': 100, 'learning_rate': 0.1, 'metric': 'rmse', 'n_jobs': -1, 'num_iterations': 1000, 'objective': 'tweedie', 'seed': 0}\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.65261\tvalid_1's rmse: 2.21753\n",
      "Early stopping, best iteration is:\n",
      "[72]\ttraining's rmse: 2.68542\tvalid_1's rmse: 2.2081\n",
      "------------------------------------\n",
      "6\n",
      "{'bagging_fraction': 0.75, 'bagging_freq': 10, 'boosting_type': 'gbdt', 'colsample_bytree': 0.75, 'early_stopping_round': 100, 'learning_rate': 0.05, 'metric': 'rmse', 'n_jobs': -1, 'num_iterations': 1000, 'objective': 'poisson', 'seed': 0}\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.69205\tvalid_1's rmse: 2.24507\n",
      "[200]\ttraining's rmse: 2.63861\tvalid_1's rmse: 2.21601\n",
      "[300]\ttraining's rmse: 2.60871\tvalid_1's rmse: 2.21212\n",
      "[400]\ttraining's rmse: 2.5828\tvalid_1's rmse: 2.21174\n",
      "[500]\ttraining's rmse: 2.56486\tvalid_1's rmse: 2.211\n",
      "[600]\ttraining's rmse: 2.54215\tvalid_1's rmse: 2.21031\n",
      "Early stopping, best iteration is:\n",
      "[565]\ttraining's rmse: 2.55055\tvalid_1's rmse: 2.20922\n",
      "------------------------------------\n",
      "7\n",
      "{'bagging_fraction': 0.75, 'bagging_freq': 10, 'boosting_type': 'gbdt', 'colsample_bytree': 0.75, 'early_stopping_round': 100, 'learning_rate': 0.05, 'metric': 'rmse', 'n_jobs': -1, 'num_iterations': 1000, 'objective': 'tweedie', 'seed': 0}\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.72664\tvalid_1's rmse: 2.22856\n",
      "[200]\ttraining's rmse: 2.64844\tvalid_1's rmse: 2.21278\n",
      "Early stopping, best iteration is:\n",
      "[172]\ttraining's rmse: 2.66174\tvalid_1's rmse: 2.20994\n",
      "------------------------------------\n",
      "8\n",
      "{'bagging_fraction': 0.75, 'bagging_freq': 10, 'boosting_type': 'gbdt', 'colsample_bytree': 0.75, 'early_stopping_round': 100, 'learning_rate': 0.075, 'metric': 'rmse', 'n_jobs': -1, 'num_iterations': 1000, 'objective': 'poisson', 'seed': 0}\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.67992\tvalid_1's rmse: 2.23533\n",
      "[200]\ttraining's rmse: 2.62375\tvalid_1's rmse: 2.22766\n",
      "[300]\ttraining's rmse: 2.57966\tvalid_1's rmse: 2.22182\n",
      "[400]\ttraining's rmse: 2.55372\tvalid_1's rmse: 2.21876\n",
      "Early stopping, best iteration is:\n",
      "[359]\ttraining's rmse: 2.56351\tvalid_1's rmse: 2.21713\n",
      "------------------------------------\n",
      "9\n",
      "{'bagging_fraction': 0.75, 'bagging_freq': 10, 'boosting_type': 'gbdt', 'colsample_bytree': 0.75, 'early_stopping_round': 100, 'learning_rate': 0.075, 'metric': 'rmse', 'n_jobs': -1, 'num_iterations': 1000, 'objective': 'tweedie', 'seed': 0}\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.67729\tvalid_1's rmse: 2.21657\n",
      "[200]\ttraining's rmse: 2.61526\tvalid_1's rmse: 2.22016\n",
      "Early stopping, best iteration is:\n",
      "[117]\ttraining's rmse: 2.65743\tvalid_1's rmse: 2.21382\n",
      "------------------------------------\n",
      "10\n",
      "{'bagging_fraction': 0.75, 'bagging_freq': 10, 'boosting_type': 'gbdt', 'colsample_bytree': 0.75, 'early_stopping_round': 100, 'learning_rate': 0.1, 'metric': 'rmse', 'n_jobs': -1, 'num_iterations': 1000, 'objective': 'poisson', 'seed': 0}\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.67335\tvalid_1's rmse: 2.23878\n",
      "[200]\ttraining's rmse: 2.60079\tvalid_1's rmse: 2.22982\n",
      "[300]\ttraining's rmse: 2.5557\tvalid_1's rmse: 2.22629\n",
      "[400]\ttraining's rmse: 2.52578\tvalid_1's rmse: 2.22528\n",
      "Early stopping, best iteration is:\n",
      "[338]\ttraining's rmse: 2.54205\tvalid_1's rmse: 2.22245\n",
      "------------------------------------\n",
      "11\n",
      "{'bagging_fraction': 0.75, 'bagging_freq': 10, 'boosting_type': 'gbdt', 'colsample_bytree': 0.75, 'early_stopping_round': 100, 'learning_rate': 0.1, 'metric': 'rmse', 'n_jobs': -1, 'num_iterations': 1000, 'objective': 'tweedie', 'seed': 0}\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.65393\tvalid_1's rmse: 2.218\n",
      "Early stopping, best iteration is:\n",
      "[70]\ttraining's rmse: 2.68026\tvalid_1's rmse: 2.20793\n",
      "------------------------------------\n",
      "12\n",
      "{'bagging_fraction': 1, 'bagging_freq': 10, 'boosting_type': 'gbdt', 'colsample_bytree': 0.75, 'early_stopping_round': 100, 'learning_rate': 0.05, 'metric': 'rmse', 'n_jobs': -1, 'num_iterations': 1000, 'objective': 'poisson', 'seed': 0}\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.7135\tvalid_1's rmse: 2.24789\n",
      "[200]\ttraining's rmse: 2.64656\tvalid_1's rmse: 2.22051\n",
      "[300]\ttraining's rmse: 2.6191\tvalid_1's rmse: 2.21844\n",
      "Early stopping, best iteration is:\n",
      "[255]\ttraining's rmse: 2.6316\tvalid_1's rmse: 2.21744\n",
      "------------------------------------\n",
      "13\n",
      "{'bagging_fraction': 1, 'bagging_freq': 10, 'boosting_type': 'gbdt', 'colsample_bytree': 0.75, 'early_stopping_round': 100, 'learning_rate': 0.05, 'metric': 'rmse', 'n_jobs': -1, 'num_iterations': 1000, 'objective': 'tweedie', 'seed': 0}\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.72599\tvalid_1's rmse: 2.22874\n",
      "[200]\ttraining's rmse: 2.64657\tvalid_1's rmse: 2.21269\n",
      "Early stopping, best iteration is:\n",
      "[158]\ttraining's rmse: 2.66981\tvalid_1's rmse: 2.21013\n",
      "------------------------------------\n",
      "14\n",
      "{'bagging_fraction': 1, 'bagging_freq': 10, 'boosting_type': 'gbdt', 'colsample_bytree': 0.75, 'early_stopping_round': 100, 'learning_rate': 0.075, 'metric': 'rmse', 'n_jobs': -1, 'num_iterations': 1000, 'objective': 'poisson', 'seed': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.68291\tvalid_1's rmse: 2.23915\n",
      "[200]\ttraining's rmse: 2.6232\tvalid_1's rmse: 2.22732\n",
      "[300]\ttraining's rmse: 2.57767\tvalid_1's rmse: 2.22419\n",
      "Early stopping, best iteration is:\n",
      "[284]\ttraining's rmse: 2.58499\tvalid_1's rmse: 2.22277\n",
      "------------------------------------\n",
      "15\n",
      "{'bagging_fraction': 1, 'bagging_freq': 10, 'boosting_type': 'gbdt', 'colsample_bytree': 0.75, 'early_stopping_round': 100, 'learning_rate': 0.075, 'metric': 'rmse', 'n_jobs': -1, 'num_iterations': 1000, 'objective': 'tweedie', 'seed': 0}\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.67852\tvalid_1's rmse: 2.21663\n",
      "Early stopping, best iteration is:\n",
      "[94]\ttraining's rmse: 2.68539\tvalid_1's rmse: 2.21517\n",
      "------------------------------------\n",
      "16\n",
      "{'bagging_fraction': 1, 'bagging_freq': 10, 'boosting_type': 'gbdt', 'colsample_bytree': 0.75, 'early_stopping_round': 100, 'learning_rate': 0.1, 'metric': 'rmse', 'n_jobs': -1, 'num_iterations': 1000, 'objective': 'poisson', 'seed': 0}\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.68391\tvalid_1's rmse: 2.23988\n",
      "[200]\ttraining's rmse: 2.60128\tvalid_1's rmse: 2.2337\n",
      "[300]\ttraining's rmse: 2.55432\tvalid_1's rmse: 2.22846\n",
      "[400]\ttraining's rmse: 2.52521\tvalid_1's rmse: 2.22477\n",
      "Early stopping, best iteration is:\n",
      "[392]\ttraining's rmse: 2.52867\tvalid_1's rmse: 2.22391\n",
      "------------------------------------\n",
      "17\n",
      "{'bagging_fraction': 1, 'bagging_freq': 10, 'boosting_type': 'gbdt', 'colsample_bytree': 0.75, 'early_stopping_round': 100, 'learning_rate': 0.1, 'metric': 'rmse', 'n_jobs': -1, 'num_iterations': 1000, 'objective': 'tweedie', 'seed': 0}\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 2.65037\tvalid_1's rmse: 2.21873\n",
      "Early stopping, best iteration is:\n",
      "[71]\ttraining's rmse: 2.67722\tvalid_1's rmse: 2.21054\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for g in ParameterGrid(param_grid):\n",
    "    print(i)\n",
    "    print(g)\n",
    "    mlflow.lightgbm.autolog() \n",
    "    model = lgb.train(g, train_set,  \n",
    "                  valid_sets = [train_set, val_set], verbose_eval = 100)\n",
    "    \n",
    "    y_test = model.predict(X_test[features])\n",
    "    X_test['demand'] = y_test\n",
    "\n",
    "    predictions = X_test[['id', 'days_from_start', 'demand']]\n",
    "    predictions = pd.pivot(predictions, index = 'id', columns = 'days_from_start', values = 'demand').reset_index()\n",
    "    predictions.columns = ['id'] + ['F' + str(i + 1) for i in range(28)]\n",
    "\n",
    "    evaluation_rows = [row for row in submission['id'] if 'evaluation' in row] \n",
    "    evaluation = submission[submission['id'].isin(evaluation_rows)]\n",
    "\n",
    "    validation = submission[['id']].merge(predictions, on = 'id')\n",
    "    final = pd.concat([validation, evaluation])\n",
    "    final.head()\n",
    "    final.to_csv('../04_submissions/lightGBM_{}.csv'.format(i), index = False)\n",
    "    i = i + 1\n",
    "    print(\"------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "print(len(ParameterGrid(param_grid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the RMSE on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = model.predict(X_test[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred = model.predict(X_val[features])\n",
    "val_score = np.sqrt(metrics.mean_squared_error(val_pred, y_val))\n",
    "X_val['demand'] = y_val\n",
    "X_val['demand_pred'] = val_pred\n",
    "X_val['abs_difference'] = abs(X_val['demand'] - X_val['demand_pred'])\n",
    "print(f'Our val rmse score is {val_score}')\n",
    "y_test = model.predict(X_test[features])\n",
    "X_test['demand'] = y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Our val mae score is {metrics.mean_absolute_error(val_pred, y_val)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We look at the mean absolute error by forecastablity in order to indestand what category needs more improvement for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val.groupby(['demand_type'])['demand_type', 'abs_difference'].agg(['mean']).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demans_vs_error = sns.scatterplot(x=X_val['demand'], y=X_val['abs_difference'])\n",
    "demans_vs_error.set_title('Distribution of error over demand')\n",
    "demans_vs_error.set_xlabel('absolute error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprisingly smooth time series has a large mean absolute error. Erratic time series has a large mean absolute error; typically time series of this type is difficult to predict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plotImp(model, X , num = 20):\n",
    "    feature_imp = pd.DataFrame({'Value':model.feature_importance(),'Feature':X.columns})\n",
    "    plt.figure(figsize=(40, 20))\n",
    "    sns.set(font_scale = 5)\n",
    "    sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", \n",
    "                                                        ascending=False)[0:num])\n",
    "    plt.title('LightGBM Features (avg over folds)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('lgbm_importances-01.png')\n",
    "    plt.show()\n",
    "plotImp(model, X_train[features], 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'item_id' and 'id' are most important features. 'days_from_start' reflect the trend of data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform predictions to the right format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = X_test[['id', 'days_from_start', 'demand']]\n",
    "predictions = pd.pivot(predictions, index = 'id', columns = 'days_from_start', values = 'demand').reset_index()\n",
    "predictions.columns = ['id'] + ['F' + str(i + 1) for i in range(28)]\n",
    "\n",
    "evaluation_rows = [row for row in submission['id'] if 'evaluation' in row] \n",
    "evaluation = submission[submission['id'].isin(evaluation_rows)]\n",
    "\n",
    "validation = submission[['id']].merge(predictions, on = 'id')\n",
    "final = pd.concat([validation, evaluation])\n",
    "final.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the submission, the features and the score to files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv('../04_submissions/lightGBM_no_fe.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = X_test.columns[~X_test.columns.isin(not_features)]\n",
    "features = features.to_list()\n",
    "features.append(str(val_score))\n",
    "features.append(str(params['objective']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../04_submissions/lgb_features_score.txt\", \"a\") as outfile:\n",
    "    outfile.write(\"\\n\".join(features))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score of this submission is 0.58584, which is better than naive prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
