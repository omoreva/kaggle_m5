{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime  import datetime  \n",
    "from datetime import timedelta  \n",
    "import feather\n",
    "import lightgbm as lgb\n",
    "from sklearn import preprocessing, metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_pickle('../01_preprocessed_data/X_train.pkl')\n",
    "y_train = pd.read_pickle('../01_preprocessed_data/y_train.pkl')\n",
    "X_val = pd.read_pickle('../01_preprocessed_data/X_val.pkl')\n",
    "y_val = pd.read_pickle('../01_preprocessed_data/y_val.pkl')\n",
    "X_test = pd.read_pickle('../01_preprocessed_data/X_test.pkl')\n",
    "submission = pd.read_csv('../00_data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train = feather.read_dataframe('../01_preprocessed_data/X_train.feather')\n",
    "#y_train = feather.read_dataframe('../01_preprocessed_data/y_train.feather')\n",
    "#X_val = feather.read_dataframe('../01_preprocessed_data/X_val.feather')\n",
    "#y_val = feather.read_dataframe('../01_preprocessed_data/y_val.feather')\n",
    "#X_test = feather.read_dataframe('../01_preprocessed_data/X_test.feather')\n",
    "#submission = pd.read_csv('../00_data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train = X_train.drop(columns = ['date', 'start_date'])\n",
    "#X_val = X_val.drop(columns = ['date', 'start_date'])\n",
    "#X_test = X_test.drop(columns = ['date', 'start_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cat = ['event_name_1', 'event_type_1', 'event_name_2', 'event_type_2']\n",
    "#for feature in cat:\n",
    "#    encoder = preprocessing.LabelEncoder()\n",
    "#    X_train[feature] = encoder.fit_transform(X_train[feature])\n",
    "#    X_val[feature] = encoder.fit_transform(X_val[feature])\n",
    "#    X_test[feature] = encoder.fit_transform(X_test[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train = X_train.drop(columns = ['avg_month'])\n",
    "#X_val = X_val.drop(columns = ['avg_month'])\n",
    "#X_test= X_test.drop(columns = ['avg_month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id',\n",
       "       'items_sold', 'date', 'weekday', 'month', 'event_name_1',\n",
       "       'event_type_1', 'event_name_2', 'event_type_2', 'snap_CA', 'snap_TX',\n",
       "       'snap_WI', 'start_date', 'days_from_start', 'start_date_from_start',\n",
       "       'sell_price', 'avg_weekday', 'avg_month', 'avg_price'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'metric': 'rmse',\n",
    "        'objective': 'regression',\n",
    "        'n_jobs': -1,\n",
    "        'seed': 0,\n",
    "        'learning_rate': 0.1,\n",
    "        'bagging_fraction': 0.75,\n",
    "        'bagging_freq': 10, \n",
    "        'colsample_bytree': 0.75}\n",
    "features = ['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'weekday', 'month', \n",
    "            'event_name_1', 'event_type_1','event_name_2', 'event_type_2',\n",
    "            'snap_CA', 'snap_TX', 'snap_WI',\n",
    "            'days_from_start', 'start_date_from_start', 'sell_price',\n",
    "           'avg_weekday', # 'avg_month', \n",
    "            'avg_price']\n",
    "train_set = lgb.Dataset(X_train[features], y_train)\n",
    "val_set = lgb.Dataset(X_val[features], y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'weekday',\n",
       "       'month', 'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2',\n",
       "       'snap_CA', 'snap_TX', 'snap_WI', 'days_from_start',\n",
       "       'start_date_from_start', 'sell_price', 'avg_weekday', 'avg_price'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[features].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 2.75018\tvalid_1's rmse: 2.38765\n",
      "[200]\ttraining's rmse: 2.67912\tvalid_1's rmse: 2.32461\n",
      "[300]\ttraining's rmse: 2.63594\tvalid_1's rmse: 2.30761\n",
      "[400]\ttraining's rmse: 2.60412\tvalid_1's rmse: 2.29149\n",
      "[500]\ttraining's rmse: 2.57988\tvalid_1's rmse: 2.27865\n",
      "[600]\ttraining's rmse: 2.55811\tvalid_1's rmse: 2.27061\n"
     ]
    }
   ],
   "source": [
    "#del x_train, y_train\n",
    "\n",
    "model = lgb.train(params, train_set, num_boost_round = 2500, early_stopping_rounds = 50, \n",
    "                  valid_sets = [train_set, val_set], verbose_eval = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred = model.predict(X_val[features])\n",
    "val_score = np.sqrt(metrics.mean_squared_error(val_pred, y_val))\n",
    "print(f'Our val rmse score is {val_score}')\n",
    "y_test = model.predict(X_test[features])\n",
    "X_test['items_sold'] = y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['items_sold'] = y_test\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission = pd.read_csv('../00_data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = X_test[['id', 'date', 'items_sold']]\n",
    "predictions = pd.pivot(predictions, index = 'id', columns = 'date', values = 'items_sold').reset_index()\n",
    "predictions.columns = ['id'] + ['F' + str(i + 1) for i in range(28)]\n",
    "\n",
    "evaluation_rows = [row for row in submission['id'] if 'evaluation' in row] \n",
    "evaluation = submission[submission['id'].isin(evaluation_rows)]\n",
    "\n",
    "validation = submission[['id']].merge(predictions, on = 'id')\n",
    "final = pd.concat([validation, evaluation])\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv('../04_submissions/lightGBM_no_fe.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.append(str(val_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../04_submissions/lgb_features_score.txt\", \"a\") as outfile:\n",
    "    outfile.write(\"\\n\".join(features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
